server:
  port: 8080
  base_url: http://localhost:8080

logging:
  level: info

providers:
  - id: openai-1
    provider: openai
    config:
      api_key: "your-openai-api-key"
      api_url: "https://api.openai.com/v1"
  - id: dummy-1
    provider: dummy
    config: {}
  - id: ollama
    provider: ollama
    config:
      api_url: "http://localhost:11434"
 
models:
  - id: gpt-4.1
    name: gpt-4.1
    provider: openai-1
    fallback:
      - dummy-model
  - id: qwen3:0.6b
    name: qwen3:0.6b
    provider: ollama
  - id: dummy-model
    name: dummy-model
    provider: dummy-1
